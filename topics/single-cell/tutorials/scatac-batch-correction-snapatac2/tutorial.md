---
layout: tutorial_hands_on

title: Multi-sample batch correction with Harmony and SnapATAC2
subtopic: scmultiomics
priority: 3
level: Intermediate
zenodo_link: https://zenodo.org/records/12683310
questions:
- Why is batch correction important during the analysis of data from multiple samples?
- How is batch correction performed on single cell ATAC-seq data?
objectives:
- Perform batch correction on a dataset collection of multiple single cell ATAC-seq samples.
- Learn how Harmony and other batch correction algorithms remove batch effects.
time_estimation: 4H
key_points:
- Batch correction is important for the integration of data from multiple experiments
- Batch correction algorithms identify similar cells and move them closer together through appropriate correction vectors.
requirements:
- type: internal
  topic_name: single-cell
  tutorials:
  - scatac-preprocessing-tenx
  - scatac-standard-processing-snapatac2
tags:
- 10x
- epigenetics
abbreviations:
    scATAC-seq: Single-cell Assay for Transposase-Accessible Chromatin using sequencing
    QC: quality control
    TSSe: transcription start site enrichment
    TSS: transcription start sites
    UMAP: Uniform Manifold Approximation and Projection
contributions:
 authorship:
  - timonschlegel
 editing:
  - dianichj
gitter: Galaxy-Training-Network/galaxy-single-cell


---



<!-- This is a comment. -->
Performing experiments in replicates is a cornerstone of modern biological science. However, when integrating data from multiple single-cell sequencing experiments, technical confounders might impact the results.
To reduce technical confounders, such as different experimenters, experimental protocols, sequencing lanes or sequencing technologies, batch correction is often beneficial.

In this tutorial, we will perform batch correction on five datasets of {scATAC-seq} data with the three algorithms *Harmony* ({% cite Korsunsky2019 %}), *Scanorama* ({% cite Hie2019 %}) and the *mutual nearest neighbor-based* ({% cite Haghverdi2018%}) algorithm *MNC-correct* ({% cite Zhang2024 %}). The {scATAC-seq} analysis will be performed with the tool suite [**SnapATAC2**](https://kzhang.org/SnapATAC2/version/2.5/index.html) ({% cite Zhang2024 %}).

{% snippet topics/single-cell/faqs/single_cell_omics.md %}

{% snippet faqs/galaxy/tutorial_mode.md %}

> <comment-title></comment-title>
>
> This tutorial is significantly based on the ["Multi-sample Pipeline" tutorial](https://kzhang.org/SnapATAC2/version/2.5/tutorials/integration.html) from **SnapATAC2**.
>
> The data analysis is performed with the same tools shown in the tutorial [Single-cell ATAC-seq standard processing with SnapATAC2]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %} ).
> That tutorial also explains the steps of the ATAC-seq analysis with SnapATAC2 in more detail.
> We recommend completing that tutorial before continuing with batch correction using SnapATAC2.
>
{: .comment}

> <agenda-title></agenda-title>
>
> In this tutorial, we will cover:
>
> 1. TOC
> {:toc}
>
{: .agenda}

# Data

In this tutorial we will analyze colon samples from multiple donors, provided by the [SnapATAC2 documentation](https://kzhang.org/SnapATAC2/version/2.5/tutorials/integration.html). The `chrom_sizes` file and the `gene_annotation` file are identical to the previous tutorial [Single-cell ATAC-seq standard processing with SnapATAC2]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %} ).
The five `colon_multisample` files have been generated by the **Cell Ranger ATAC 2.0.0** pipeline from 10X to generate a [*Fragments File*](https://support.10xgenomics.com/single-cell-atac/software/pipelines/latest/output/fragments).


> <details-title>Chromosome sizes </details-title>
>
> - A chromosome sizes file can be generated using the tool {% tool [Compute sequence length](toolshed.g2.bx.psu.edu/repos/devteam/fasta_compute_length/fasta_compute_length/1.0.3) %}.
> - The reference genome can either be selected from cached genomes or uploaded to the galaxy history.
>
{: .details}

First, we will import the datasets into Galaxy. Next, we will organize all `colon_multisample` datasets into a collection. Using collections helps streamline the workflow, making the subsequent analysis steps more efficient.

{% snippet faqs/galaxy/histories_datasets_vs_collections.md %}


## Get data

> <hands-on-title> Data Upload </hands-on-title>
>
> 1. Create a new history for this tutorial
> 2. Import the files from [Zenodo]({{ page.zenodo_link }}) or from
>    the shared data library
>
>
>    ```
>    {{ page.zenodo_link }}/files/colon_multisample_01.gz
>    {{ page.zenodo_link }}/files/colon_multisample_02.gz
>    {{ page.zenodo_link }}/files/colon_multisample_03.gz
>    {{ page.zenodo_link }}/files/colon_multisample_04.gz
>    {{ page.zenodo_link }}/files/colon_multisample_05.gz
>    {{ page.zenodo_link }}/files/chrom_sizes.txt
>    {{ page.zenodo_link }}/files/gencode.v46.annotation.gtf.gz
>    ```
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
>    > <warning-title>Large file sizes!</warning-title>
>    > - The `colon_multisample` datasets are quite large. The entire tutorial requires approximately 50 GB of storage.
>    > - To reduce storage you can change the {% icon galaxy-gear %} **Upload Configuration** to *Defer dataset resolution* for the upload of the `colon_multisample` datasets.
>    > - This will delete the datasets after the first analysis step and helps in reducing storage.
>    > - You can also permanently delete datasets, which are no longer required.
>    >
>    >   {% snippet faqs/galaxy/datasets_deleting.md %}
>    >
>    {: .warning}
>
> 3. Rename the datasets
>    - {% icon galaxy-pencil %} **Rename** the file `gencode.v46.annotation.gtf.gz` to `gene_annotation.gtf.gz`
>
>    {% snippet faqs/galaxy/datasets_rename.md %}
>
> 4. Check that the datatypes of the `colon_multisample` files are set to `bed`
>
>    {% snippet faqs/galaxy/datasets_change_datatype.md datatype="bed" %}
>
> 5. Create a dataset collection with all `colon_multisample` datasets and rename the collection to `Colon Multisample Fragments`.
>
>    {% snippet faqs/galaxy/collections_build_list.md name="Colon Multisample Fragments" %}
>
{: .hands_on}

# SnapATAC2 preprocessing and filtering

With our data imported and the collection assembled, we can now begin the {scATAC-seq} data preprocessing with SnapATAC2.

The first step is to import the datasets into an AnnData object using the *pp.import_data* tool. Next, the `{TSSe}` will be calculated, serving as a `{QC}` metric to selectively filter droplets containing high-quality cells.

> <details-title>AnnData format </details-title>
>
> - The [**AnnData**](https://anndata.readthedocs.io/en/latest/) format was initially developed for the [**Scanpy**](https://scanpy.readthedocs.io/en/stable/index.html) package and is now a widely accepted data format to store annotated data matrices in a space-efficient manner.
>
> ![Anndata format]({% link topics/single-cell/images/scatac-standard-snapatac2/anndata_schema.svg %} "AnnData format stores a count matrix `X` together with annotations of observations (i.e., cells) `obs`, variables (i.e., genes) `var`, and unstructured annotations `uns`.")
>
{: .details}

> <hands-on-title> Preprocessing and QC </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Import data fragment files and compute basic QC metrics, using 'pp.import_data'`
>        - {% icon param-collection %} *"Fragment file, optionally compressed with gzip or zstd"*: `Colon Multisample Fragments` (Input dataset collection)
>        - {% icon param-file %} *"A tabular file containing chromosome names and sizes"*: `chrom_sizes.txt` (Input dataset)
>        - *"Number of unique fragments threshold used to filter cells"*: `1000`
> 2. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Compute the TSS enrichment score (TSSe) for each cell, using 'metrics.tsse'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas` (dataset collection output of **pp.import_data** {% icon tool %})
>        - {% icon param-file %} *"GTF/GFF file containing the gene annotation"*: `gene_annotation` (Input dataset)
> 3. {% icon galaxy-pencil %} Rename the generated collection to `Colon Multisample AnnDatas TSSe`.
>
> 4. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the TSS enrichment vs. number of fragments density figure, using 'pl.tsse'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas TSSe` (output of **metrics.tsse** {% icon tool %})
> 5. {% icon galaxy-eye %} Inspect a few exemplary `.png` outputs of the collection
>
> ![TSSe plots against number of unique fragments]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/tsse-colon01-colon02.png %}"Examplary plots of TSSe from <code>colon_multisample_01</code> and <code>colon_multisample_02</code>")
>
> High-quality cells can be identified in the plot of {TSSe} scores against a number of unique fragments for each cell.
>
> > <question-title></question-title>
> >
> > 1. Where are high-quality cells typically located on a {TSSe} plot?
> > 2. Based on these plots, how should the filtering threshold be set?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. The cells in the upper right are high-quality cells, enriched for {TSS}. Fragments in the lower left represent low-quality cells or empty droplets and should be filtered out.
> > > 2. Setting the minimum {TSSe} to 7.0 will filter out the lowest quality droplets without loosing too much data.
> > >
> > {: .solution}
> >
> {: .question}
>
{: .hands_on}

## Filtering the count matrices

The {TSSe} threshold balances data retention and quality control. In our dataset, the {TSSe} distributions indicate substantial differences in sample quality between batches. To retain as much biological data as possible, we will use a broader filter (e.g., minimum {TSSe} = 7.0).

Standard {TSSe} Thresholds
- **Strict (TSSe ≥ 10–15)**: High-confidence cells.
- **Moderate (TSSe ≥ 7–10)**: Balances data retention and quality but may include lower-quality cells.
- **Broad (TSSe ≥ 5–7)**: Maximizes retention but increases the risk of including lower-quality data.

Choosing the Right Cutoff
- If sample quality varies, a **moderate threshold (≥7.0)** helps retain more data.
- If high-quality data is required, **stricter filtering (≥10.0)** is recommended.
- Inspect {TSSe} distributions to determine the most suitable threshold for your dataset.

> <hands-on-title> Filtering </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Filter cell outliers based on counts and numbers of genes expressed, using 'pp.filter_cells'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas TSSe` (output of **metrics.tsse** {% icon tool %})
>        - *"Minimum TSS enrichemnt score required for a cell to pass filtering"*: `7.0`
>
> 2. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Generate cell by bin count matrix, using 'pp.add_tile_matrix'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas filtered` (output of **pp.filter_cells** {% icon tool %})
>        - *"The size of consecutive genomic regions used to record the counts"*: `5000`
>
> 3. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Perform feature selection, using 'pp.select_features'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas tile_matrix` (output of **pp.add_tile_matrix** {% icon tool %})
>        - *"Number of features to keep"*: `50000`
>
>    > <details-title> Bin size and features </details-title>
>    >
>    > - *pp.add_tile_matrix* divides the genome into a specified number of bins, depending on the bin size (f.ex. 5000bp). For each bin, the ATAC-seq reads of individual cells are checked to determine if a read is located in the bin. This is counted as a feature and stored under `n_vars` in the AnnData object.
>    >    - Increasing the bin size greatly reduces compute time at the cost of some biological data.
>    >    - For this reason, the bin size 5000bp has been selected for the colon datasets. In the [previous tutorial]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#feature-selection), the lower bin size of 500bp was chosen, since fewer cells were analyzed.
>    > - *pp.select_features* uses the previously identified features to select the most accessible features for further analysis.
>    >    - The parameter *"Number of features to keep"* determines the upper limit of features which can be selected.
>    >    - Similarly to the *bin_size*, the *Number of Features to keep* can also impact downstream clustering. This was demonstrated in the [previous tutorial]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#feature-selection ).
>    {: .details}
>
> 4. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Compute probability of being a doublet using the scrublet algorithm, using 'pp.scrublet'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas features` (output of **pp.select_features** {% icon tool %})
>
> 5. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Remove doublets according to the doublet probability or doublet score, using 'pp.filter_doublets'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Colon Multisample AnnDatas scrublet` (output of **pp.scrublet** {% icon tool %})
>
{: .hands_on}

# Concatenate the Collection
Before we can continue with the analysis and batch correction, we need to extract the datasets out of the collection and merge them into a single AnnData object.

## Extracting datasets from a collection
This is achieved in two steps:
1. The first dataset is extracted from the collection using *Extract dataset*
2. Afterwards, the first dataset will be removed from the collection. This is done by extracting element identifiers and filtering the collection with the name of the first dataset.

> <comment-title>  </comment-title>
> - It is also possible to manually remove a dataset from a collection.
> - However, manually removing datasets can not be implemented in Galaxy workflows. In contrast the automatic method, shown here, can be represented in a workflow and is therefore much better scalable.
{: .comment}

> <hands-on-title> Extract datasets </hands-on-title>
>
> 1. {% tool [Extract element from collection](__EXTRACT_DATASET__) %} with the following parameters:
>    - {% icon param-collection %} *"Input List"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>    - *"How should a dataset be selected?"*: `The first dataset`
> 2. {% tool [Extract element identifiers](toolshed.g2.bx.psu.edu/repos/iuc/collection_element_identifiers/collection_element_identifiers/0.0.2) %} with the following parameters:
>    - {% icon param-collection %} *"Dataset collection"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>
> 3. {% tool [Select first](Show beginning1) %} with the following parameters:
>    - *"Select first"*: `1`
>    - {% icon param-file %} *"from"*: `Element identifiers` (output of **Extract element identifiers** {% icon tool %})
> 4. {% tool [Filter collection](__FILTER_FROM_FILE__) %} with the following parameters:
>    - {% icon param-collection %} *"Input Collection"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>    - *"How should the elements to remove be determined?"*: `Remove if identifiers are PRESENT in file`
>        - {% icon param-file %} *"Filter out identifiers present in"*: `select_first` (output of **Select first** {% icon tool %})
> 5. {% icon galaxy-pencil %} Rename the filtered collection to `Colon Multisample 02-05`
>
{: .hands_on}

## Concatenating all AnnData files

> <hands-on-title> Concatenate </hands-on-title>
>
> 1. {% tool [Manipulate AnnData](toolshed.g2.bx.psu.edu/repos/iuc/anndata_manipulate/anndata_manipulate/0.10.3+galaxy0) %} with the following parameters:
>    - {% icon param-file %} *"Annotated data matrix"*: `colon_multisample_01` (output of **Extract dataset** {% icon tool %})
>    - *"Function to manipulate the object"*: `Concatenate along the observations axis`
>        - {% icon param-collection %} *"Annotated data matrix to add"*: `Colon Multisample 02-05` (output of **Filter collection** {% icon tool %})
>        - *"Join method"*: `Intersection of variables`
>        - *"Key to add the batch annotation to obs"*: `batch`
>
>    > <details-title>Issues with concatenation</details-title>
>    > - The runtime of this operation depends on the dataset size. For `colon_multisample` datasets, concatenation may take up to 1 hour.
>    > - For larger datasets, the tool's allocated memory may be insufficient, causing the operation to fail. In that case, you will see the following error message:
>    >
>    >   ```
>    >                Fatal error: Exit code 137 ()
>    >   ```
>    > - In this case, report the issue so that administrators can increase the memory limit, allowing the job to complete successfully.
>    >
>    >   {% snippet faqs/galaxy/analysis_troubleshooting_reporting.md %}
>    >
>    {: .details}
>
> 2. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData`
> 3. {% icon galaxy-eye %} Inspect the general information of `Multisample AnnData`
>
>    > <tip-title>Inspecting AnnData objects</tip-title>
>    > * Many toolsets producing outputs in *AnnData* formats in Galaxy, provide the general information by default:
>    >    * Click on the name of the dataset in the history to expand it. The general Anndata information will be given in the expanded box.
>    >    * Alternatively, expand the dataset and click on {% icon details %}*Dataset Details*. Scroll to Job Information and inspect the Tool Standard Output.
>    > * If a tool does not provide general AnnData information or a more specific query is needed, you can use {% tool [Inspect AnnData](toolshed.g2.bx.psu.edu/repos/iuc/anndata_inspect/anndata_inspect/0.10.3+galaxy0) %}.
>    {: .tip}
>
>    ```
>    AnnData object with n_obs × n_vars = 34372 × 606219
>     obs: 'n_fragment', 'frac_dup', 'frac_mito', 'tsse', 'doublet_probability', 'doublet_score', 'batch'
>     var: 'count-0', 'selected-0', 'count-1', 'selected-1', 'count-2', 'selected-2', 'count-3', 'selected-3', 'count-4', 'selected-4'
>     obsm: 'fragment_paired'
>    ```
>
> > <question-title></question-title>
> >
> > 1. How many colon cells are present in this AnnData object?
> > 2. What does the 'batch' annotation indicate?
> > 3. What do the 'count-' and 'selected-' annotations represent?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. There are 34,372 cells.
> > > 2. The 'batch' annotation labels cells according to their sample number (0–4). This annotation will later be used by batch correction algorithms to generate clusters from multiple samples.
> > > 3. 'count' and 'selected' are variable annotations representing detected and selected features. The sample number (0–4) indicates the dataset that generated these annotations.
> > >
> > {: .solution}
>  {: .question}
>
{: .hands_on}

# Dimension Reduction
Now that all samples have been concatenated into a single AnnData object, the most accessible features of the combined count matrix must be selected. The previously chosen features were sample-specific and cannot be used for dimensionality reduction. Therefore, the most accessible features will be reselected, followed by dimensionality reduction using *matrix-free spectral embedding*.


> <hands-on-title> Spectral Embedding </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Perform feature selection, using 'pp.select_features'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData` (output of **Manipulate AnnData** {% icon tool %})
>        - *"Number of features to keep"*: `50000`
>
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and clustering"*: `Perform dimensionality reduction using Laplacian Eigenmap ('tl.spectral')`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData features` (output of **pp.select_features** {% icon tool %})
>        - *"Distance metric"*: `cosine`
>
> 3. {% icon galaxy-pencil %} Rename the output AnnData object to `Multisample AnnData spectral`
>
{: .hands_on}


## Control Without Batch Correction
Batch effects can be visualized using a `{UMAP}` projection, where samples are colored by their batch annotation (`obs: 'batch'`).
> <hands-on-title> UMAP Projection Without Batch Correction </hands-on-title>
>
> 1. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute UMAP using 'tl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData spectral` (output of **tl.spectral** {% icon tool %})
>
> 2. {% icon galaxy-pencil %} Rename the output AnnData object to `Multisample AnnData UMAP`.
>
> 3. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData UMAP` (output of **tl.umap** {% icon tool %})
>        - *"Color"*: `batch`
>        - *"Height of the plot"*: `500`
>
> 4. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-No Batch Correction`.
>
> 5. {% icon galaxy-eye %} Inspect the `.png` output.
>
> ![UMAP plot before batch correction]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-no_harmony-spectral.png %})
>
> > <question-title></question-title>
> >
> > 1. How do batch effects appear in this plot?
> > 2. What would a plot without batch effects look like?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. Batch effects appear as distinct clusters where samples are unevenly distributed. For example, in the upper right corner, each batch forms a separate group. These differences are likely technical artifacts rather than true biological variation.
> > > 2. A plot without batch effects would show cells from all samples evenly mixed, with no distinct clusters corresponding to individual batches.
> > >
> > {: .solution}
>  {: .question}
>
{: .hands_on}

# Batch correction
After confirming the presence of batch effects, they should be removed using correction algorithms. **SnapATAC2** provides three batch correction methods: *Harmony*, *MNC-correct*, and *Scanorama*. To determine the most suitable algorithm for your dataset, compare the outputs of each method.

> <details-title> Batch correction algorithms </details-title>
> - Batch correction algorithms adjust the cell-by-feature count matrix to account for batch-specific differences between samples.
> - Batch effects can arise from various technical sources, such as sequencing lanes, plates, protocols, and handling. Additionally, biological factors, including tissue types, species, and inter-individual variation, can also contribute to batch effects {% cite Luecken2021 %}.
> - Many batch correction algorithms have been developed, with most scATAC-seq methods adapted from scRNA-seq batch removal techniques.
> - *Harmony* {% cite Korsunsky2019 %} is a principal component analysis (PCA)-based method that leverages lower-dimensional data to assign cells to new clusters. It prioritizes multi-sample clustering to integrate datasets by computing linear correction factors for each batch and cluster, iteratively adjusting cell positions until optimal batch correction is achieved.
>
>   ![Graphical abstract of Harmony batch correction]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/harmony-graphical-abstract.png %})
>
> - *Scanorama* {% cite Hie2019 %} performs panorama stiching, to find and merge overlapping cell types.
>
>   ![Graphical abstract of Scanorama batch correction]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/scanorama-graphical-abstract.png %})
>
> - *MNC-correct* {% cite Zhang2024 %} is a modified version of the *mutual nearest neighbor* algorithm {% cite Haghverdi2018 %}. It calculates centroids for batch-specific clusters and identifies pairs of mutual nearest centroids (MNC) across batches. Correction vectors then align the batches in the same plane. Additionally, *MNC-correct* can be run iteratively to refine corrections for optimal alignment.
>
>   ![Graphical abstract of MNC-correct batch correction]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/mnn-graphical-abstract.png %})
>
{: .details}

We will first use *Harmony* to correct batch effects, followed by testing the other methods.
> <hands-on-title> Batch correction and visualization</hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Use harmonypy to integrate different experiments,using 'pp.harmony'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData UMAP` (output of **tl.umap** {% icon tool %})
>
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute Umap, using 'tl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony` (output of **pp.harmony** {% icon tool %})
>        - *"Use the indicated representation in `.obsm`"*: `X_spectral_harmony`
>        - *"`adata.obs` key under which t add cluster labels"*: `umap_harmony`
>
> 2. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData harmony UMAP`
>
>    > <comment-title> Key for Cluster Labels </comment-title>
>    > - Adding the new *UMAP embeddings* under the key `umap_harmony` preserves the non-batch-corrected embeddings in the AnnData object.
>    >   - Alternatively, leaving this parameter empty will overwrite the existing embeddings.
>    {: .comment}
>
> 4. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding, using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony UMAP` (output of **tl.umap** {% icon tool %})
>        - *"Color"*: `batch`
>        - *"Use the indicated representation in .obsm"*: `X_umap_harmony`
>        - *"Height of the plot"*: `500`
>
> 5. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-harmony`
>
> 6. {% icon galaxy-eye %} Inspect the `.png` output
>
>  ![UMAP plot of Batch correction with Harmony]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-harmony-spectral.png %})
>
> > <question-title></question-title>
> >
> > 1. How did *Harmony* affect the appearance of this plot?
> > 2. Are there areas in the plot where batch effects persist?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. *Harmony* has successfully removed most batch effects. Notably, the center-left groups have merged into a single larger group containing all batches.
> > > 2. Yes, some batch effects remain, particularly in the upper-right corner, where batch-specific colors do not fully overlap. However, this could also be due to certain samples having fewer cells, leading to underrepresentation in clusters of rare cell types. Therefore, it is unclear whether *Harmony* has completely eliminated all batch effects.
> > >
> > {: .solution}
>  {: .question}
>
>
{: .hands_on}

> <details-title>Batch Correction with Scanorama and MNC-correct</details-title>
> - Other batch correction methods can be applied using {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %}, including *pp.mnc_correct* and *pp.scanorama_integrate*.
>   - For *MNC-correct*, the number of iterations can be adjusted.
> - To determine the optimal batch correction method, it is recommended to test different algorithms and parameter settings.
> - Example outputs from *Scanorama* and *MNC-correct* are shown below:
>
>  ![Batch correction UMAP plots of MNC-correct with different settings and Scanorama]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/mnc-correct-scanorama-umap-spectral.png %} "UMAP plots of batch correction with different methods. (a) Batch correction with MNC-correct and default settings. (b) Batch correction with Scanorama. (c) Batch correction with MNC-correct and 30 iterations.")
>
> > <question-title></question-title>
> >
> > - Compare these plots with the output of *Harmony*. Which algorithm is best-suited for the colon datasets?
> >
> > > <solution-title></solution-title>
> > >
> > > - *Harmony* achieved the best batch integration, as it produced the fewest single-batch groups. *Scanorama* and *MNC-correct* (with default settings) did not integrate the batches as effectively. However, *MNC-correct* with 30 iterations significantly reduced batch effects and could also be used for further analysis.
> > >
> > {: .solution}
>  {: .question}
>
{: .details}


# Clustering of the batch corrected samples
The analysis can now continue using the same methods outlined in the [standard pathway]({% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}). The batch-corrected embeddings are clustered and visualized using the *Leiden* algorithm.

> <hands-on-title> Leiden clustering and visualization </hands-on-title>
>
> 1. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute a neighborhood graph of observations, using 'pp.knn'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony UMAP` (output of **tl.umap** {% icon tool %})
>        - *"The key for the matrix"*: `X_spectral_harmony`
>
>    > <tip-title>Matrix Keys</tip-title>
>    >
>    > - Each batch correction algorithm stores its corrected matrix under a specific key:
>    >   - *Harmony*: `X_spectral_harmony`
>    >   - *MNC-correct*: `X_spectral_mnn`
>    >   - *Scanorama*: `X_spectral_scanorama`
>    > - These keys are stored in the AnnData object under `'obsm'`.
>    >
>    {: .tip}
>
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Cluster cells into subgroups, using 'tl.leiden'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony knn` (output of **pp.knn** {% icon tool %})
>        - *"Whether to use the Constant Potts Model (CPM) or modularity"*: `modularity`
>
> 3. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData harmony leiden`
>
> 4. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding, using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `anndata_out` (output of **tl.leiden** {% icon tool %})
>        - *"Color"*: `leiden`
>        - *"Use the indicated representation in .obsm"*: `X_umap_harmony`
>        - *"Height of the plot"*: `500`
>
> 5. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-harmony-leiden`
>
> 6. {% icon galaxy-eye %} Inspect the `.png` output
>
>  ![UMAP plot of Batch-corrected leiden clusters]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-harmony-leiden.png %})
>
{: .hands_on}

After integrating the datasets and clustering the cells, the scATAC-seq analysis can proceed with downstream analysis. This includes [cell cluster annotation]({% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#cell-cluster-annotation) and differential peak analysis.
> <comment-title></comment-title>
>
> The **SnapATAC2** tools for differential peak analysis are available in Galaxy, but no GTN training materials are currently provided. Until a tutorial is available, you can refer to the **SnapATAC2** documentation for a [tutorial on differential peak analysis](https://kzhang.org/SnapATAC2/version/2.6/tutorials/diff.html).
>
> The tools are available in Galaxy under {% tool [SnapATAC2 Peaks and Motif](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_peaks_and_motif/snapatac2_peaks_and_motif/2.6.4+galaxy1) %}.
>
{: .comment}


# Conclusion
{% icon congratulations %} Well done, you’ve made it to the end! You might want to consult your results with this [control history](https://usegalaxy.eu/u/timonschlegel/h/multisample-batch-correction-with-harmony-and-snapatac2), or check out the [full workflow](https://usegalaxy.eu/u/timonschlegel/w/multisample-batch-correction-with-snapatac2-and-harmony) for this tutorial.

In this tutorial, we integrated five {scATAC-seq} colon samples using a scalable Galaxy workflow. We compared different batch integration algorithms to identify the most suitable method for our data. Finally, we clustered the cells to prepare the data for downstream analysis.

![SnapATAC2 batch correction pipeline]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/Batch-correction-pipeline-overview.png %})
